{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import dill\n",
    "import mir_eval.display\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import os, sys, time, datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "    \n",
    "print (\"[info] Current Time   : \" + datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "print (\"[info] Python Version : \" + sys.version.split('\\n')[0] )\n",
    "print (\"[info] Working Dir    : \" + os.getcwd())\n",
    "#print (\"[info] Library load done.\")\n",
    "\n",
    "\n",
    "# define function to load midi file\n",
    "def load_midi_file(name):\n",
    "    raw_midi_data = pretty_midi.PrettyMIDI(name)\n",
    "    raw_midi_data.instruments[0].is_drum = False\n",
    "    \n",
    "    tc_times, tempo_changes = raw_midi_data.get_tempo_changes()    \n",
    "    print (\"Midi file tempo : {} BPM\".format(tempo_changes[0]))\n",
    "    \n",
    "    midi_bpm = tempo_changes[0]\n",
    "    single_beat_period = 60.0 / tempo_changes[0]\n",
    "    single_bar_period = 4.0 * single_beat_period\n",
    "\n",
    "    print (\"Single beat length: {} Sec.\".format(single_beat_period))\n",
    "    #print (\"Single Bar period: {} Sec.\".format(single_bar_period))\n",
    "    \n",
    "    # midi file: 120 BPM \n",
    "    # 1 bar = 2 Sec. = 16 x 16th note\n",
    "    # 1/2 Bar = 1 Sec. = 8 x 16th note\n",
    "    # total midi length : 340 Bar\n",
    "    #                     680 Sec\n",
    "    #                     5440 x 16th note\n",
    "\n",
    "    # Lower the midi file sampling resolution for simplicity\n",
    "    midi_pno_roll = raw_midi_data.get_piano_roll(fs=8)\n",
    "    #midi_pno_roll = raw_midi_data.get_piano_roll(fs=tempo_changes[0]/60.0)\n",
    "\n",
    "    # get midi file array row and col size\n",
    "    midi_row_num = midi_pno_roll.shape[0]\n",
    "    midi_col_num = midi_pno_roll.shape[1]\n",
    "\n",
    "    print (\"Total bars: {}\".format(midi_col_num/16))\n",
    "    print (\"Midi file data array shape: {}\".format([midi_row_num, midi_col_num]))    \n",
    "    \n",
    "    return(raw_midi_data)\n",
    "\n",
    "\n",
    "# Defince plot function, use librosa's specshow function for displaying the piano roll\n",
    "def plot_piano_roll(raw_midi_data, start_pitch, end_pitch, fs=8):\n",
    "    librosa.display.specshow(raw_midi_data.get_piano_roll(fs)[start_pitch:end_pitch],\n",
    "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
    "                             fmin=pretty_midi.note_number_to_hz(start_pitch),\n",
    "                             cmap='binary'\n",
    "                            )\n",
    "\n",
    "def plot_first_four_bar(raw_midi_data, bar_n):\n",
    "    # Get and downbeat times\n",
    "    beats = raw_midi_data.get_beats()\n",
    "    start_beat = raw_midi_data.get_downbeats()\n",
    "\n",
    "    # Draw drum midi piano roll\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    plot_piano_roll(raw_midi_data, start_pitch=20, end_pitch=60)\n",
    "\n",
    "    # Draw beat position and bar position\n",
    "    mir_eval.display.events(beats, color='blue', lw=1)\n",
    "    mir_eval.display.events(start_beat, color='red', lw=2)\n",
    "\n",
    "    # Only display 0 - 8 Sec. midi data for simplicity\n",
    "    plt.xlim(0, bar_n*2);\n",
    "    \n",
    "    # set plot tittle\n",
    "    plt.title('The first four bar drum channel data')\n",
    "    \n",
    "    \n",
    "def analyse_drum(raw_midi_data):    \n",
    "    # check how many different sound are used in midi array\n",
    "    midi_pno_roll = raw_midi_data.get_piano_roll(fs=8)\n",
    "\n",
    "    # get midi file array row and col size\n",
    "    midi_row_num = midi_pno_roll.shape[0]\n",
    "    midi_col_num = midi_pno_roll.shape[1]\n",
    "\n",
    "    # create an empty list to store activated notes/notes count\n",
    "    exist_note_type_list = []\n",
    "    note_counts = []\n",
    "\n",
    "    # sweep whole midi file array, check activated note\n",
    "    for note in range(0, midi_row_num):\n",
    "        for beat in range(0, midi_col_num):\n",
    "            element = midi_pno_roll[note, beat]\n",
    "            # if a note is activated\n",
    "            if element!=0:\n",
    "                # if note is not seen before\n",
    "                if note not in exist_note_type_list:\n",
    "                    # put note number into a list\n",
    "                    exist_note_type_list.append(note)\n",
    "                    # add a new note count elements\n",
    "                    note_counts.append(1)\n",
    "                else: # if note is already in list\n",
    "                    # check the existing note index\n",
    "                    note_idx, = np.where(np.array(exist_note_type_list)==note)[0]\n",
    "                    # note count + 1\n",
    "                    note_counts[note_idx] = note_counts[note_idx] + 1\n",
    "\n",
    "    note_types = len(exist_note_type_list)    \n",
    "    print (\"Note types: {} types\".format(note_types))\n",
    "    print (\"Activated MIDI notes: {}\".format(exist_note_type_list))\n",
    "    print (\"Activated counts: {}\".format(note_counts))    \n",
    "    \n",
    "    \n",
    "    # instruments mapping from note number to GM instruments\n",
    "    #\n",
    "    # 36 : KD              (KD)         # 44 : Pedal HH     (PdHH)\n",
    "    # 37 : SD ring shot    (SDrs)       # 47 : Low Mid-Tom  (LMT)\n",
    "    # 38 : SD              (SD)         # 50 : High Tom     (HT)\n",
    "    # 42 : Closed HH       (CsdHH)      # 51 : Ride Cymbal  (RC)\n",
    "    # 43 : High Floor Tom  (HFT)        # 56 : Cowbell      (CB)\n",
    "\n",
    "    # set plot label names\n",
    "    note_type_name = ['KD', 'SDrs', 'SD', 'CsdHH', 'HFT', 'PdHH', 'LMT', 'HT', 'RC', 'CB']\n",
    "\n",
    "    # Generate bar plot with size (8,4)\n",
    "    plt.figure(figsize=(8,4))\n",
    "\n",
    "    # Draw Bar plot\n",
    "    plt.bar(range(10), height=note_counts)\n",
    "\n",
    "    # set Label\n",
    "    plt.xticks(range(10), note_type_name);\n",
    "    \n",
    "    # set plot tittle\n",
    "    plt.title('Drum note counts')\n",
    "\n",
    "    \n",
    "# reduce data complexity into only n type sound\n",
    "def get_simplified_data(raw_midi_data, keep_sound):\n",
    "\n",
    "    # Lower the midi file sampling resolution for simplicity\n",
    "    midi_pno_roll = raw_midi_data.get_piano_roll(fs=8)\n",
    "\n",
    "    # get midi file array row and col size\n",
    "    midi_row_num = midi_pno_roll.shape[0]\n",
    "    midi_col_num = midi_pno_roll.shape[1]        \n",
    "        \n",
    "    #exist_note_type_list = [36, 38, 42]\n",
    "    note_types = len(keep_sound)\n",
    "\n",
    "    # create an empty array to store simplified midi data\n",
    "    reduced_midi_array = np.zeros([note_types, midi_col_num])\n",
    "\n",
    "    # copy data from original full midi data array to reduced array\n",
    "    for idx, note in enumerate(keep_sound):\n",
    "        reduced_midi_array[idx, :] = midi_pno_roll[note, :]\n",
    "\n",
    "    # add closed SD into SD\n",
    "    #reduced_midi_array[1, :] = reduced_midi_array[1, :] + midi_pno_roll[37, :]\n",
    "\n",
    "    # make data [0 or 1]\n",
    "    reduced_midi_array[reduced_midi_array>=0.5] = 1\n",
    "    reduced_midi_array[reduced_midi_array<0.5] = 0\n",
    "    reduced_midi_array = reduced_midi_array.astype(np.int)\n",
    "    \n",
    "    # show result data format\n",
    "    #print (\"#####  result data format  #####\")\n",
    "    print (\"###  Input Data  ###\")\n",
    "    \n",
    "    #print (\"Total bars: {}  (16 beat/bar)\".format(midi_col_num/16))\n",
    "    #print (\"The first bar([:, 0:16]): \\n{}\".format(reduced_midi_array[:reduced_midi_array.shape[0], :16]))\n",
    "            \n",
    "    \n",
    "    # check how many types of non-repeated drum pattern\n",
    "    \n",
    "    beats_per_bar = 16\n",
    "    total_bars = np.int(midi_col_num/beats_per_bar)\n",
    "    print (\"  >> Original MIDI file patterns: {}\".format(total_bars))\n",
    "    \n",
    "    print (\"  >> Array shape: {}\".format(reduced_midi_array.shape))\n",
    "\n",
    "    # create an empty list to store non-repeated drum pattern\n",
    "    pattern_list = []\n",
    "\n",
    "    # sweep patterns across whole \"reduced_midi_array\"\n",
    "    for bar in range(0, total_bars):\n",
    "        # create empty array to store single pattern\n",
    "        single_drum_ptn = np.zeros([note_types, beats_per_bar])\n",
    "\n",
    "        # calculate beat start and beat end\n",
    "        beat_start = bar * beats_per_bar\n",
    "        beat_end = (bar+1) * beats_per_bar\n",
    "\n",
    "        # move data into single pattern empty array\n",
    "        single_drum_ptn[:, :] = reduced_midi_array[:, beat_start:beat_end]\n",
    "\n",
    "        # if this is the first pattern\n",
    "        if bar==0:\n",
    "            # store it into pattern_list\n",
    "            pattern_list.append(single_drum_ptn)\n",
    "        else:\n",
    "            # initialize a flag to store pattern existence status\n",
    "            ptn_is_exist_in_ptns_list = 0\n",
    "            for bar_idx in range(0, len(pattern_list)):\n",
    "                if np.array_equal(single_drum_ptn, pattern_list[bar_idx]):   # if this pattern is already in pattern_list\n",
    "                    ptn_is_exist_in_ptns_list = 1                            # set this flag from 0 to 1\n",
    "            if ptn_is_exist_in_ptns_list==0:                                 # if this pattern is not seen in pattern_list before\n",
    "                pattern_list.append(single_drum_ptn)                         # store it into pattern_list\n",
    "\n",
    "                \n",
    "    num_types = len(pattern_list)\n",
    "    single_pattern_shape = pattern_list[0].shape\n",
    "    \n",
    "    for x in range(0, num_types):\n",
    "        pattern_list[x][pattern_list[x]>0.50] = 0.70\n",
    "        pattern_list[x][pattern_list[x]<=0.50] = -0.70\n",
    "    \n",
    "    print (\"###  Output Data  ###\")\n",
    "    \n",
    "    #print (\"All original 16 beat drum pattern: {}\".format(midi_col_num/16))\n",
    "    print (\"  >> Simplified non-repeated patterns: {}\".format(num_types))\n",
    "    \n",
    "    #print (\"Total types of drum pattern: {}\".format(num_types))\n",
    "    print (\"  >> pattern data format: {}\".format(single_pattern_shape))                    \n",
    "    \n",
    "            \n",
    "    return(pattern_list)\n",
    "    \n",
    "    \n",
    "def make_large_64x64(input_array):\n",
    "    large_array = np.zeros([64, 64])    \n",
    "    for row in range(0, 64):                \n",
    "        for col in range(0, 64):\n",
    "            large_array[row, col] = input_array[row//16, col//4]    \n",
    "    return large_array   \n",
    "\n",
    "\n",
    "def sample_small_4x16(input_array):\n",
    "    small_array = np.zeros([4, 16])\n",
    "    for row in range(0, 64):                \n",
    "        for col in range(0, 64):\n",
    "            small_array[row//16, col//4] = small_array[row//16, col//4] + input_array[row, col]\n",
    "    small_array = small_array/64.0\n",
    "    return small_array\n",
    "    \n",
    "    \n",
    "    \n",
    "def save_data(data, file_name):\n",
    "    with open(file_name, 'wb') as saving_file:             \n",
    "        dill.dump(data, saving_file)\n",
    "\n",
    "    print (\"File \\\"{}\\\" is saved !\".format(file_name))\n",
    "    \n",
    "\n",
    "\n",
    "import argparse\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import dill\n",
    "from pylab import plt\n",
    "#%matplotlib inline\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "    \n",
    "#print (\"[info] Current Time   : \" + datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "#print (\"[info] Python Version : \" + sys.version.split('\\n')[0] )\n",
    "#print (\"[info] Working Dir    : \" + os.getcwd())\n",
    "#print (\"[info] Library load done.\")\n",
    "\n",
    "\n",
    "class Config:\n",
    "    n_epochs = 40000\n",
    "    batch_size = 32\n",
    "    g_lr = 2e-5\n",
    "    d_lr = 8e-6\n",
    "    z_dim = 256\n",
    "    data_h = 4\n",
    "    data_w = 16    \n",
    "    channels = 1\n",
    "    sample_interval = 1\n",
    "    use_cuda = False\n",
    "    #use_cuda = True\n",
    "    \n",
    "config = Config()\n",
    "data_shape = (config.channels, config.data_h, config.data_w)\n",
    "\n",
    "\n",
    "class md_dataset(Dataset):\n",
    "    \"\"\" midi dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data here.\n",
    "    def __init__(self, file_name):\n",
    "        \n",
    "        with open(file_name, 'rb') as saved_file:\n",
    "            load_data = dill.load(saved_file)\n",
    "        \n",
    "        self.data = load_data\n",
    "        self.data_h = self.data[0].shape[0]\n",
    "        self.data_w = self.data[0].shape[1]\n",
    "        self.len = len(load_data)\n",
    "        \n",
    "        self.total_ary = np.zeros([self.data_h, self.len*self.data_w])\n",
    "        \n",
    "        for x in range(0, self.len):\n",
    "            self.total_ary[:, x*16:(x+1)*16] = self.data[x][:, :]\n",
    "            \n",
    "        self.total_ary = self.total_ary.astype(np.float32)\n",
    "        \n",
    "        self.total_ary = self.total_ary.reshape([1, self.total_ary.shape[0], self.total_ary.shape[1]])\n",
    "        \n",
    "        self.total_ary = torch.from_numpy(self.total_ary)\n",
    "\n",
    "    def __getitem__(self, index):     \n",
    "        #out = torch.from_numpy(self.data[index].reshape([1,self.data_h,self.data_w]).astype(np.float32))\n",
    "        out = self.total_ary[:, :, index*16:(index+1)*16]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "# Define Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # set fully connected layer\n",
    "        self.fc_model = nn.Sequential(\n",
    "                                nn.Linear(config.z_dim, 128),\n",
    "                                nn.LeakyReLU(0.01, inplace=True),\n",
    "                                nn.Dropout(p=0.4),\n",
    "            \n",
    "                                nn.Linear(128, 256),\n",
    "                                nn.LeakyReLU(0.01, inplace=True),\n",
    "                                nn.Dropout(p=0.3),\n",
    "            \n",
    "                                nn.Linear(256, 512),\n",
    "                                nn.LeakyReLU(0.01, inplace=True),\n",
    "                                nn.Dropout(p=0.2),  \n",
    "\n",
    "                                nn.Linear(512, 1024),\n",
    "                                nn.LeakyReLU(0.01, inplace=True),\n",
    "                                nn.Dropout(p=0.1),              \n",
    "\n",
    "                                nn.Linear(1024, 4096),\n",
    "                                nn.LeakyReLU(0.01, inplace=True),\n",
    "            \n",
    "                                nn.Linear(4096, 4*16),\n",
    "                                nn.Tanh()\n",
    "                )        \n",
    "        \n",
    "    # define G forward network calculation\n",
    "    def forward(self, g_input):\n",
    "        fc_out = self.fc_model(g_input)\n",
    "        fc_out_4d = fc_out.view(g_input.size(0), 1, 4, 16)\n",
    "        \n",
    "        return fc_out_4d\n",
    "\n",
    "    \n",
    "    \n",
    "# Define Discriminator \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # set convolulation layer\n",
    "        self.conv = nn.Sequential(\n",
    "                              nn.Conv2d(1 ,2048 ,(2, 2) ,(2 ,1) ,0 ,bias=False),\n",
    "                              nn.BatchNorm2d(2048),\n",
    "                              nn.LeakyReLU(0.20 ,inplace=True),\n",
    "\n",
    "                              nn.Conv2d(2048 ,512 ,(2, 2) ,(2, 1) ,0 ,bias=False),\n",
    "                              nn.BatchNorm2d(512),\n",
    "                              nn.LeakyReLU(0.20 ,inplace=True),\n",
    "\n",
    "                              nn.Conv2d(512 ,256 ,(2, 2) ,(1, 1) ,0 ,bias=False),\n",
    "                              nn.BatchNorm2d(256),\n",
    "                              nn.LeakyReLU(0.20 ,inplace=True),\n",
    "\n",
    "                              nn.Conv2d(256 ,32 ,(2, 2) ,(1, 1) ,0 ,bias=False),\n",
    "                              nn.BatchNorm2d(32),\n",
    "                              nn.LeakyReLU(0.20 ,inplace=False),  \n",
    "                )\n",
    "        \n",
    "        # set fully connected layer\n",
    "        self.fc = nn.Sequential(\n",
    "                            nn.Linear(5376, 1),    \n",
    "                )\n",
    "        \n",
    "    # define D forward network calculation\n",
    "    def forward(self, d_input):\n",
    "        conv_out = self.conv(d_input)        \n",
    "        fc_input = conv_out.view(d_input.size(0), -1)\n",
    "        score = self.fc(fc_input)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    \n",
    "\n",
    "def nv_cuda(xs):\n",
    "    if torch.cuda.is_available() and config.use_cuda:\n",
    "        if not isinstance(xs, (list, tuple)):\n",
    "            return xs.cuda()\n",
    "        else:\n",
    "            return [x.cuda() for x in xs]\n",
    "        \n",
    "    else:\n",
    "        if not isinstance(xs, (list, tuple)):\n",
    "            return xs\n",
    "        else:\n",
    "            return [x for x in xs]\n",
    "\n",
    "        \n",
    "def gradient_penalty(x, f):\n",
    "    # interpolation\n",
    "    shape = [x.size(0)] + [1] * (x.dim() - 1)\n",
    "    alpha = nv_cuda(torch.rand(shape))\n",
    "    beta = nv_cuda(torch.rand(x.size()))\n",
    "    \n",
    "    y = x + 0.5 * x.std() * beta\n",
    "    z = x + alpha * (y - x)\n",
    "\n",
    "    # gradient penalty\n",
    "    z = nv_cuda(Variable(z, requires_grad=True))\n",
    "    o = f(z)\n",
    "    g = grad(o, z, grad_outputs=nv_cuda(torch.ones(o.size())), create_graph=True)[0].view(z.size(0), -1)\n",
    "    gp = ((g.norm(p=2, dim=1) - 1)**2).mean()\n",
    "\n",
    "    return gp * 10.0\n",
    "\n",
    "\n",
    "def get_mini_batch(in_tensor):\n",
    "    basic_unit = config.batch_size//8\n",
    "    out_tensor = torch.cat([in_tensor[           0:basic_unit*1], \n",
    "                            in_tensor[basic_unit*1:basic_unit*2], \n",
    "                            in_tensor[basic_unit*2:basic_unit*3], \n",
    "                            in_tensor[basic_unit*3:basic_unit*4],\n",
    "                            in_tensor[basic_unit*4:basic_unit*5], \n",
    "                            in_tensor[basic_unit*5:basic_unit*6], \n",
    "                            in_tensor[basic_unit*6:basic_unit*7],\n",
    "                            in_tensor[basic_unit*7:basic_unit*8]], \n",
    "                           dim=2)\n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "def get_diff(input_tensor):\n",
    "    # create tensor to store diff value\n",
    "    out_tensor = torch.zeros(input_tensor.shape[0], \n",
    "                         input_tensor.shape[1],\n",
    "                         input_tensor.shape[2]*2,\n",
    "                         input_tensor.shape[3])\n",
    "    \n",
    "    out_tensor = Variable(out_tensor)\n",
    "    \n",
    "    if config.use_cuda:\n",
    "        out_tensor = out_tensor.cuda()\n",
    "    \n",
    "    # calculate original tensor\n",
    "    out_tensor[:,:,0:4,:] = input_tensor\n",
    "        \n",
    "    # save time axis diff tensor\n",
    "    out_tensor[:,:,4:8,1:] = input_tensor[:,:,:,:15]\n",
    "    out_tensor[:,:,4:8,:] = (input_tensor[:,:,:,:] - out_tensor[:,:,4:8,:] + 1.0) * 0.5\n",
    "    \n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "\n",
    "def count_parameters(generator, discriminator):\n",
    "    gs  = sum(np.prod(list(p.size())) for p in generator.parameters())\n",
    "    ds  = sum(np.prod(list(q.size())) for q in discriminator.parameters())\n",
    "    \n",
    "    print ('Number of [G/D/Total] params: [%d/%d/%d]' %(gs, ds, (gs + ds)))\n",
    "\n",
    "\n",
    "\n",
    "# Loss function\n",
    "#adversarial_loss = torch.nn.BCELoss()\n",
    "#adversarial_loss = torch.nn.BCEWithLogitsLoss()\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "#Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "Tensor = torch.cuda.FloatTensor if config.use_cuda else torch.FloatTensor\n",
    "\n",
    "\n",
    "# Optimizers\n",
    "#optimizer_G = torch.optim.Adam(generator.parameters(),     lr=config.lr,     betas=(0.5, 0.99))\n",
    "#optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=config.lr*0.5, betas=(0.5, 0.99))\n",
    "#optimizer_G = torch.optim.RMSprop(generator.parameters(),     lr=config.lr, alpha=0.9)\n",
    "#optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=config.lr, alpha=0.9)\n",
    "\n",
    "def set_model_gpu(generator, discriminator):\n",
    "    if config.use_cuda:\n",
    "        generator.cuda()\n",
    "        discriminator.cuda()\n",
    "        loss.cuda()\n",
    "\n",
    "\n",
    "def reload_models(generator, discriminator, reload):\n",
    "    if reload:\n",
    "        generator.load_state_dict(torch.load('g_model.pt'))\n",
    "        discriminator.load_state_dict(torch.load('d_model.pt')) \n",
    "        print('model parameters are reloaded.')\n",
    "    else:\n",
    "        print('No reload.')\n",
    "      \n",
    "    \n",
    "def get_labels():\n",
    "    real_label = Variable(Tensor(config.batch_size//8, 1).fill_(1.00), requires_grad=False)\n",
    "    fake_label = Variable(Tensor(config.batch_size//8, 1).fill_(0.00), requires_grad=False)\n",
    "    \n",
    "    return real_label, fake_label\n",
    "        \n",
    "\n",
    "def plot_rhythm(rhythm):\n",
    "    plt.imshow(np.flipud(rhythm), cmap='binary')\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "def show_training_status(epoch, config, g_loss, d_loss, fake_data): \n",
    "    if (epoch%config.sample_interval == 0) and (epoch>0):     \n",
    "                    \n",
    "        print (\"[Epoch %d/%d] [G loss: %f] [D loss: %f]\" % (epoch, config.n_epochs,\n",
    "                                                            g_loss.data.cpu().numpy(), \n",
    "                                                            d_loss.data.cpu().numpy())\n",
    "              )\n",
    "\n",
    "        print(datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "        \n",
    "        # plot rhythm        \n",
    "        plt.imshow(np.flipud(fake_data.data[:1].squeeze()), cmap='binary')\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def generate_rhythm(generator, num):\n",
    "    \n",
    "    # set maximum number to 20\n",
    "    num = min(20, num)\n",
    "    \n",
    "    # generate 100 non repeated pattern:\n",
    "    z = Variable(Tensor(np.random.normal(0, 1, (num*4, config.z_dim)))) * 100.0\n",
    "\n",
    "    pattern_list = []\n",
    "\n",
    "    for x in range(0, num*4):\n",
    "        pattern = generator(z).data[x].squeeze().cpu().numpy()\n",
    "\n",
    "        pattern[pattern>0.25] = 1.0\n",
    "        pattern[pattern<=0.25] = 0.0\n",
    "\n",
    "        repeat_ptn = False\n",
    "\n",
    "        if len(pattern_list)==0:\n",
    "            pattern_list.append(pattern)\n",
    "        else:\n",
    "            for k in range(0, len(pattern_list)):\n",
    "                if np.array_equal(pattern, pattern_list[k]):\n",
    "                    repeat_ptn = True\n",
    "                    break\n",
    "            if (repeat_ptn==False):\n",
    "                pattern_list.append(pattern)\n",
    "\n",
    "        if len(pattern_list)>=num:\n",
    "            #print(\"sweeped pattern: {}\".format(x+1))\n",
    "            break\n",
    "\n",
    "    print (\"generated non-repeated pattern: {}\".format(len(pattern_list)))\n",
    "    \n",
    "    for x in range(0, num):\n",
    "        print (\"rhythm: {}\".format(x+1))\n",
    "        plot_rhythm(pattern_list[x])\n",
    "    \n",
    "    return pattern_list    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "  \n",
    "from midiutil.MidiFile import MIDIFile\n",
    "\n",
    "def write_midi(rhythm, file_name):\n",
    "    \n",
    "    ptn_types = len(rhythm)\n",
    "    output_bars = []\n",
    "\n",
    "    # repeat each pattern for 4 times\n",
    "    for ptrn_n in range (0, ptn_types):\n",
    "        for _ in range(4):\n",
    "            output_bars.append(rhythm[ptrn_n])\n",
    "        #print (\"output pattern : {}\".format(ptrn_n+1))\n",
    "        \n",
    "        \n",
    "    # create your MIDI object\n",
    "    midi_file = MIDIFile(numTracks=1, adjust_origin=True, file_format=1)     # only 1 track\n",
    "\n",
    "    # only need 1 track, track \"0\"\n",
    "    track = 0   \n",
    "    # start at the beginning\n",
    "    time = 0    \n",
    "    # set track channel, 0 = piano, 9 = Drum kit\n",
    "    channel = 9\n",
    "    # set track volume\n",
    "    volume = 124\n",
    "\n",
    "    # set track name\n",
    "    midi_file.addTrackName(track, time, \"GAN Drum\")\n",
    "    # set track tempo\n",
    "    midi_file.addTempo(track, time, 120)\n",
    "\n",
    "    # set unit time for a 16th note\n",
    "    u16b_d = 0.25 # 1 drum beat = 0.25 Sec.\n",
    "    # create time array\n",
    "    u16b = list(range(0, 16+1))\n",
    "    for x in range(0, 16):\n",
    "        u16b[x] = (x) * u16b_d\n",
    "\n",
    "    #drum_note_num = np.array([36, 37, 38, 42, 43, 44, 47, 50, 51, 56])\n",
    "    drum_note_num = np.array([36, 37, 40, 42])\n",
    "\n",
    "    # fill midi note into drum track\n",
    "    for bar in range(len(output_bars)):\n",
    "        bar_acc = bar * 16 * u16b_d    \n",
    "        for y in range(0, 16):\n",
    "            for x in range(0, drum_note_num.shape[0]):\n",
    "                if (output_bars[bar][x,y] > 0.0):\n",
    "                    pitch = drum_note_num[x]\n",
    "                    time = bar_acc + u16b[y]             \n",
    "                    duration = u16b_d        \n",
    "                    midi_file.addNote(track, channel, pitch, time, duration, volume)\n",
    "\n",
    "            \n",
    "    # write it to disk\n",
    "    #output_file_name = \"gg_drum.mid\"\n",
    "    output_file_name = file_name\n",
    "    with open(output_file_name, 'wb') as out_file:\n",
    "        midi_file.writeFile(out_file)\n",
    "\n",
    "    print (\"MIDI file {} is saved, Total {} type of MIDI\".format(file_name, int(len(output_bars)/4)))\n",
    "    #print (\"You can use DAW to transfer MIDI to audio now.\")\n",
    "\n",
    "       \n",
    "    \n",
    "# output drum midi\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def syn_midi(file_name, samp_rate):\n",
    "    input_midi = file_name\n",
    "    #samp_rate = 44100\n",
    "    output_file = '{}.wav'.format(file_name.split(\".\")[0])\n",
    "\n",
    "    # run MIDI to audio synthesis\n",
    "    syn_cmd = \"fluidsynth -ni sf_2_GeneralUser.sf2 {} -F tmp.wav -r {}\".format(input_midi, samp_rate)\n",
    "    os.system(syn_cmd)\n",
    "\n",
    "    #use only 16-bit mono sound, and do volume normalization\n",
    "    y, sr = librosa.load('tmp.wav', sr=samp_rate, mono=True)\n",
    "    y = y*0.80/np.max([np.abs(np.max(y)), np.abs(np.min(y))])\n",
    "    sf.write(output_file, (y * np.iinfo(np.int16).max).astype(np.int16), sr, 'PCM_16')\n",
    "    os.system(\"rm tmp.wav\")\n",
    "\n",
    "    print(\"MIDI to Audio transfer is done, synthesized file name: {}\".format(output_file))\n",
    "    #print(\"downloading file for playback...\")\n",
    "\n",
    "    #play audio wave file\n",
    "    #ipd.Audio(output_file, rate=samp_rate)\n",
    "\n",
    "\n",
    "# remove seaborn style\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
